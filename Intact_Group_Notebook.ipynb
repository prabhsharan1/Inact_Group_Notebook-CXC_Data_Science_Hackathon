{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### The goal of this notebook is to classify medical transcriptions to medical specialties. The scope of work will be given as follows:\n",
        "1. Load the datasets provided by the client\n",
        "2. Preprocess the data using sentence segmentation\n",
        "  *Data cleaning - Determining what words/sentences are important\n",
        "  *Tokenize - sentence splitting\n",
        "  *lower case\n",
        "  *stemming - removing tenses\n",
        "  *stop words - a, the, and, as, etc.\n",
        "  *lemmatization - simplify words\n",
        "3. Use feature engineering to vectorize the transcriptions\n",
        "  *tf-idf, word2vec, etc.\n",
        "4. Determine and build the best model for the training set\n",
        "  *rand forest, CNN, RNN, (Naive Bayes) etc.\n",
        "5. Evaluate the model based on a F1 score\n"
      ],
      "metadata": {
        "id": "UfheFktZW_MP"
      },
      "id": "UfheFktZW_MP"
    },
    {
      "cell_type": "markdown",
      "id": "f7bb892c",
      "metadata": {
        "id": "f7bb892c"
      },
      "source": [
        "### 1 - Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8001a2b4",
      "metadata": {
        "id": "8001a2b4",
        "outputId": "e898bc42-3c1b-4f89-8584-bfcc22d4a0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         medical_specialty                                      transcription  \\\n",
              "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
              "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
              "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
              "3                Radiology  REFERRING DIAGNOSIS: , Motor neuron disease.,P...   \n",
              "4   Emergency Room Reports  CHIEF COMPLAINT: , Dental pain.,HISTORY OF PRE...   \n",
              "\n",
              "   labels  \n",
              "0       0  \n",
              "1       1  \n",
              "2       1  \n",
              "3       2  \n",
              "4       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df5c5ded-12a5-4855-aaef-3dc8890b14c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medical_specialty</th>\n",
              "      <th>transcription</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Emergency Room Reports</td>\n",
              "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Surgery</td>\n",
              "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Surgery</td>\n",
              "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Radiology</td>\n",
              "      <td>REFERRING DIAGNOSIS: , Motor neuron disease.,P...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emergency Room Reports</td>\n",
              "      <td>CHIEF COMPLAINT: , Dental pain.,HISTORY OF PRE...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df5c5ded-12a5-4855-aaef-3dc8890b14c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df5c5ded-12a5-4855-aaef-3dc8890b14c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df5c5ded-12a5-4855-aaef-3dc8890b14c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_set = 'https://raw.githubusercontent.com/jkeomany/DS_Hackathon_2023/main/new_train.csv'\n",
        "test_set = 'https://raw.githubusercontent.com/jkeomany/DS_Hackathon_2023/main/new_test.csv'\n",
        "train_df = pd.read_csv(train_set, index_col = 0)\n",
        "test_df = pd.read_csv(test_set, index_col = 0)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b326d130",
      "metadata": {
        "id": "b326d130"
      },
      "source": [
        "### Train Set Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c349df00",
      "metadata": {
        "scrolled": true,
        "id": "c349df00",
        "outputId": "512aefa7-6917-4854-9885-edd77af1711e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Surgery                          863\n",
              " Consult - History and Phy.       410\n",
              " Cardiovascular / Pulmonary       309\n",
              " Orthopedic                       289\n",
              " Radiology                        213\n",
              " General Medicine                 209\n",
              " Gastroenterology                 176\n",
              " Neurology                        170\n",
              " SOAP / Chart / Progress Notes    135\n",
              " Urology                          134\n",
              " Obstetrics / Gynecology          123\n",
              " Discharge Summary                 87\n",
              " ENT - Otolaryngology              82\n",
              " Neurosurgery                      71\n",
              " Hematology - Oncology             68\n",
              " Ophthalmology                     67\n",
              " Emergency Room Reports            63\n",
              " Nephrology                        63\n",
              " Pediatrics - Neonatal             55\n",
              " Pain Management                   54\n",
              " Psychiatry / Psychology           45\n",
              " Office Notes                      38\n",
              " Podiatry                          35\n",
              " Dermatology                       21\n",
              " Dentistry                         21\n",
              " Cosmetic / Plastic Surgery        19\n",
              " Letters                           19\n",
              " Endocrinology                     16\n",
              " Physical Medicine - Rehab         16\n",
              " Bariatrics                        15\n",
              " IME-QME-Work Comp etc.            12\n",
              " Chiropractic                      12\n",
              " Sleep Medicine                    12\n",
              " Diets and Nutritions               9\n",
              " Speech - Language                  8\n",
              " Autopsy                            7\n",
              " Hospice - Palliative Care          6\n",
              " Allergy / Immunology               6\n",
              " Rheumatology                       6\n",
              " Lab Medicine - Pathology           5\n",
              "Name: medical_specialty, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_df[\"medical_specialty\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df8c8f3",
      "metadata": {
        "id": "9df8c8f3"
      },
      "source": [
        "### Sample Transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4b315a",
      "metadata": {
        "id": "4b4b315a",
        "outputId": "d22e2895-5d42-4ce1-dd55-1b1dea97e11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('REASON FOR THE VISIT:,  Very high PT/INR.,HISTORY: , The patient is an '\n",
            " '81-year-old lady whom I met last month when she came in with pneumonia and '\n",
            " 'CHF.  She was noticed to be in atrial fibrillation, which is a chronic '\n",
            " 'problem for her.  She did not want to have Coumadin started because she said '\n",
            " 'that she has had it before and the INR has had been very difficult to '\n",
            " 'regulate to the point that it was dangerous, but I convinced her to restart '\n",
            " 'the Coumadin again.  I gave her the Coumadin as an outpatient and then the '\n",
            " 'INR was found to be 12.  So, I told her to come to the emergency room to get '\n",
            " 'vitamin K to reverse the anticoagulation.,PAST MEDICAL HISTORY:,1.  '\n",
            " 'Congestive heart failure.,2.  Renal insufficiency.,3.  Coronary artery '\n",
            " 'disease.,4.  Atrial fibrillation.,5.  COPD.,6.  Recent pneumonia.,7.  '\n",
            " 'Bladder cancer.,8.  History of ruptured colon.,9.  Myocardial '\n",
            " 'infarction.,10.  Hernia repair.,11.  Colon resection.,12.  Carpal tunnel '\n",
            " 'repair.,13.  Knee surgery.,MEDICATIONS:,1.  Coumadin.,2.  Simvastatin.,3.  '\n",
            " 'Nitrofurantoin.,4.  Celebrex.,5.  Digoxin.,6.  Levothyroxine.,7.  '\n",
            " 'Vicodin.,8.  Triamterene and hydrochlorothiazide.,9.  Carvedilol.,SOCIAL '\n",
            " 'HISTORY:  ,She does not smoke and she does not drink.,PHYSICAL '\n",
            " 'EXAMINATION:,GENERAL:  Lady in no distress.,VITAL SIGNS:  Blood pressure '\n",
            " '100/46, pulse of 75, respirations 12, and temperature 98.2.,HEENT:  Head is '\n",
            " 'normal.,NECK:  Supple.,LUNGS:  Clear to auscultation and percussion.,HEART:  '\n",
            " 'No S3, no S4, and no murmurs.,ABDOMEN:  Soft.,EXTREMITIES:  Lower '\n",
            " 'extremities, no edema.,ASSESSMENT:,1.  Atrial fibrillation.,2.  '\n",
            " 'Coagulopathy, induced by Coumadin.,PLAN: , Her INR at the office was 12.  I '\n",
            " 'will repeat it, and if it is still elevated, I will give vitamin K 10 mg in '\n",
            " '100 mL of D5W and then send her home and repeat the PT/INR next week.  I '\n",
            " 'believe at this time that it is too risky to use Coumadin in her case '\n",
            " 'because of her age and comorbidities, the multiple medications that she '\n",
            " 'takes and it is very difficult to keep an adequate level of anticoagulation '\n",
            " 'that is safe for her.  She is prone to a fall and this would be a big '\n",
            " 'problem.  We will use one aspirin a day instead of the anticoagulation.  She '\n",
            " 'is aware of the risk of stroke, but she is very scared of the '\n",
            " 'anticoagulation with Coumadin and does not want to use the Coumadin at this '\n",
            " 'time and I understand.  We will see her as an outpatient.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(train_df.transcription[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Preprocessing"
      ],
      "metadata": {
        "id": "xi6GzVFXC_5v"
      },
      "id": "xi6GzVFXC_5v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following will use spacy, NLTK, the transcription data usable. Our first preprocessing stage will assume medical text needs to be tokenized, lemmatized, lower cased, and have an optional ability to remove punctuation. After analyzing the model, we will iteratively determine if certain data cleaning features should be added or removed.\n",
        "\n",
        "Preprocessing features include\n",
        "\n",
        "\n",
        "1.   Lower Case\n",
        "2.   Tokenization\n",
        "3.   Lemmatization\n",
        "4.   [Optional] Punctuation Removal -> Modify block starting line 38\n",
        "\n"
      ],
      "metadata": {
        "id": "8YFVf7LAS5ID"
      },
      "id": "8YFVf7LAS5ID"
    },
    {
      "cell_type": "code",
      "source": [
        "#import punkt model inside nltk library to use work tokenizer\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RImJYMtKDLh8",
        "outputId": "ff01b1f6-cd98-464f-a383-88fb167320d5"
      },
      "id": "RImJYMtKDLh8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lower_and_tokenize function"
      ],
      "metadata": {
        "id": "9N-CFPJpISzU"
      },
      "id": "9N-CFPJpISzU"
    },
    {
      "cell_type": "code",
      "source": [
        "# lower_and_tokenize(document) turns all the words of the document lower case\n",
        "#   and seperates the string into an array of individual tokens (words, spaces\n",
        "#   punctuation, etc.)\n",
        "# Returns: Document (string)\n",
        "def lower_and_tokenize(document):\n",
        "  lower_case_doc=document.lower()\n",
        "  return nltk.word_tokenize(lower_case_doc)"
      ],
      "metadata": {
        "id": "tlmcjFjLGY9L"
      },
      "id": "tlmcjFjLGY9L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test lower_and_tokenize"
      ],
      "metadata": {
        "id": "vVpghMVKHyP4"
      },
      "id": "vVpghMVKHyP4"
    },
    {
      "cell_type": "code",
      "source": [
        "print(lower_and_tokenize(train_df.transcription[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTFkE0f9H2dK",
        "outputId": "655f7a06-2841-4ef3-cd4d-18da4aea06ab"
      },
      "id": "PTFkE0f9H2dK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['reason', 'for', 'the', 'visit', ':', ',', 'very', 'high', 'pt/inr.', ',', 'history', ':', ',', 'the', 'patient', 'is', 'an', '81-year-old', 'lady', 'whom', 'i', 'met', 'last', 'month', 'when', 'she', 'came', 'in', 'with', 'pneumonia', 'and', 'chf', '.', 'she', 'was', 'noticed', 'to', 'be', 'in', 'atrial', 'fibrillation', ',', 'which', 'is', 'a', 'chronic', 'problem', 'for', 'her', '.', 'she', 'did', 'not', 'want', 'to', 'have', 'coumadin', 'started', 'because', 'she', 'said', 'that', 'she', 'has', 'had', 'it', 'before', 'and', 'the', 'inr', 'has', 'had', 'been', 'very', 'difficult', 'to', 'regulate', 'to', 'the', 'point', 'that', 'it', 'was', 'dangerous', ',', 'but', 'i', 'convinced', 'her', 'to', 'restart', 'the', 'coumadin', 'again', '.', 'i', 'gave', 'her', 'the', 'coumadin', 'as', 'an', 'outpatient', 'and', 'then', 'the', 'inr', 'was', 'found', 'to', 'be', '12.', 'so', ',', 'i', 'told', 'her', 'to', 'come', 'to', 'the', 'emergency', 'room', 'to', 'get', 'vitamin', 'k', 'to', 'reverse', 'the', 'anticoagulation.', ',', 'past', 'medical', 'history', ':', ',1.', 'congestive', 'heart', 'failure.,2', '.', 'renal', 'insufficiency.,3', '.', 'coronary', 'artery', 'disease.,4', '.', 'atrial', 'fibrillation.,5', '.', 'copd.,6', '.', 'recent', 'pneumonia.,7', '.', 'bladder', 'cancer.,8', '.', 'history', 'of', 'ruptured', 'colon.,9', '.', 'myocardial', 'infarction.,10', '.', 'hernia', 'repair.,11', '.', 'colon', 'resection.,12', '.', 'carpal', 'tunnel', 'repair.,13', '.', 'knee', 'surgery.', ',', 'medications', ':', ',1.', 'coumadin.,2', '.', 'simvastatin.,3', '.', 'nitrofurantoin.,4', '.', 'celebrex.,5', '.', 'digoxin.,6', '.', 'levothyroxine.,7', '.', 'vicodin.,8', '.', 'triamterene', 'and', 'hydrochlorothiazide.,9', '.', 'carvedilol.', ',', 'social', 'history', ':', ',', 'she', 'does', 'not', 'smoke', 'and', 'she', 'does', 'not', 'drink.', ',', 'physical', 'examination', ':', ',general', ':', 'lady', 'in', 'no', 'distress.', ',', 'vital', 'signs', ':', 'blood', 'pressure', '100/46', ',', 'pulse', 'of', '75', ',', 'respirations', '12', ',', 'and', 'temperature', '98.2.', ',', 'heent', ':', 'head', 'is', 'normal.', ',', 'neck', ':', 'supple.', ',', 'lungs', ':', 'clear', 'to', 'auscultation', 'and', 'percussion.', ',', 'heart', ':', 'no', 's3', ',', 'no', 's4', ',', 'and', 'no', 'murmurs.', ',', 'abdomen', ':', 'soft.', ',', 'extremities', ':', 'lower', 'extremities', ',', 'no', 'edema.', ',', 'assessment', ':', ',1.', 'atrial', 'fibrillation.,2', '.', 'coagulopathy', ',', 'induced', 'by', 'coumadin.', ',', 'plan', ':', ',', 'her', 'inr', 'at', 'the', 'office', 'was', '12.', 'i', 'will', 'repeat', 'it', ',', 'and', 'if', 'it', 'is', 'still', 'elevated', ',', 'i', 'will', 'give', 'vitamin', 'k', '10', 'mg', 'in', '100', 'ml', 'of', 'd5w', 'and', 'then', 'send', 'her', 'home', 'and', 'repeat', 'the', 'pt/inr', 'next', 'week', '.', 'i', 'believe', 'at', 'this', 'time', 'that', 'it', 'is', 'too', 'risky', 'to', 'use', 'coumadin', 'in', 'her', 'case', 'because', 'of', 'her', 'age', 'and', 'comorbidities', ',', 'the', 'multiple', 'medications', 'that', 'she', 'takes', 'and', 'it', 'is', 'very', 'difficult', 'to', 'keep', 'an', 'adequate', 'level', 'of', 'anticoagulation', 'that', 'is', 'safe', 'for', 'her', '.', 'she', 'is', 'prone', 'to', 'a', 'fall', 'and', 'this', 'would', 'be', 'a', 'big', 'problem', '.', 'we', 'will', 'use', 'one', 'aspirin', 'a', 'day', 'instead', 'of', 'the', 'anticoagulation', '.', 'she', 'is', 'aware', 'of', 'the', 'risk', 'of', 'stroke', ',', 'but', 'she', 'is', 'very', 'scared', 'of', 'the', 'anticoagulation', 'with', 'coumadin', 'and', 'does', 'not', 'want', 'to', 'use', 'the', 'coumadin', 'at', 'this', 'time', 'and', 'i', 'understand', '.', 'we', 'will', 'see', 'her', 'as', 'an', 'outpatient', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lower_punct_tokenize function"
      ],
      "metadata": {
        "id": "-EPlPDonJPKP"
      },
      "id": "-EPlPDonJPKP"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# lower_and_tokenize(document) turns all the words of the document lower case.\n",
        "#   , removes all punctuation, and seperates the string into an array of \n",
        "#   individual tokens (words, spaces, etc)\n",
        "# Returns: Document (string)\n",
        "def lower_punct_tokenize(document):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  lower_case_doc=document.lower()\n",
        "  return tokenizer.tokenize(lower_case_doc)"
      ],
      "metadata": {
        "id": "Bi_pPMvxJTSq"
      },
      "id": "Bi_pPMvxJTSq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lower_punct_tokenize function test"
      ],
      "metadata": {
        "id": "FsjEqoO0Jv_d"
      },
      "id": "FsjEqoO0Jv_d"
    },
    {
      "cell_type": "code",
      "source": [
        "print(lower_punct_tokenize(train_df.transcription[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8r1dUNyJ0ka",
        "outputId": "f9be2935-3951-4cc8-fb5d-c2202ee2bf6e"
      },
      "id": "J8r1dUNyJ0ka",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['reason', 'for', 'the', 'visit', 'very', 'high', 'pt', 'inr', 'history', 'the', 'patient', 'is', 'an', '81', 'year', 'old', 'lady', 'whom', 'i', 'met', 'last', 'month', 'when', 'she', 'came', 'in', 'with', 'pneumonia', 'and', 'chf', 'she', 'was', 'noticed', 'to', 'be', 'in', 'atrial', 'fibrillation', 'which', 'is', 'a', 'chronic', 'problem', 'for', 'her', 'she', 'did', 'not', 'want', 'to', 'have', 'coumadin', 'started', 'because', 'she', 'said', 'that', 'she', 'has', 'had', 'it', 'before', 'and', 'the', 'inr', 'has', 'had', 'been', 'very', 'difficult', 'to', 'regulate', 'to', 'the', 'point', 'that', 'it', 'was', 'dangerous', 'but', 'i', 'convinced', 'her', 'to', 'restart', 'the', 'coumadin', 'again', 'i', 'gave', 'her', 'the', 'coumadin', 'as', 'an', 'outpatient', 'and', 'then', 'the', 'inr', 'was', 'found', 'to', 'be', '12', 'so', 'i', 'told', 'her', 'to', 'come', 'to', 'the', 'emergency', 'room', 'to', 'get', 'vitamin', 'k', 'to', 'reverse', 'the', 'anticoagulation', 'past', 'medical', 'history', '1', 'congestive', 'heart', 'failure', '2', 'renal', 'insufficiency', '3', 'coronary', 'artery', 'disease', '4', 'atrial', 'fibrillation', '5', 'copd', '6', 'recent', 'pneumonia', '7', 'bladder', 'cancer', '8', 'history', 'of', 'ruptured', 'colon', '9', 'myocardial', 'infarction', '10', 'hernia', 'repair', '11', 'colon', 'resection', '12', 'carpal', 'tunnel', 'repair', '13', 'knee', 'surgery', 'medications', '1', 'coumadin', '2', 'simvastatin', '3', 'nitrofurantoin', '4', 'celebrex', '5', 'digoxin', '6', 'levothyroxine', '7', 'vicodin', '8', 'triamterene', 'and', 'hydrochlorothiazide', '9', 'carvedilol', 'social', 'history', 'she', 'does', 'not', 'smoke', 'and', 'she', 'does', 'not', 'drink', 'physical', 'examination', 'general', 'lady', 'in', 'no', 'distress', 'vital', 'signs', 'blood', 'pressure', '100', '46', 'pulse', 'of', '75', 'respirations', '12', 'and', 'temperature', '98', '2', 'heent', 'head', 'is', 'normal', 'neck', 'supple', 'lungs', 'clear', 'to', 'auscultation', 'and', 'percussion', 'heart', 'no', 's3', 'no', 's4', 'and', 'no', 'murmurs', 'abdomen', 'soft', 'extremities', 'lower', 'extremities', 'no', 'edema', 'assessment', '1', 'atrial', 'fibrillation', '2', 'coagulopathy', 'induced', 'by', 'coumadin', 'plan', 'her', 'inr', 'at', 'the', 'office', 'was', '12', 'i', 'will', 'repeat', 'it', 'and', 'if', 'it', 'is', 'still', 'elevated', 'i', 'will', 'give', 'vitamin', 'k', '10', 'mg', 'in', '100', 'ml', 'of', 'd5w', 'and', 'then', 'send', 'her', 'home', 'and', 'repeat', 'the', 'pt', 'inr', 'next', 'week', 'i', 'believe', 'at', 'this', 'time', 'that', 'it', 'is', 'too', 'risky', 'to', 'use', 'coumadin', 'in', 'her', 'case', 'because', 'of', 'her', 'age', 'and', 'comorbidities', 'the', 'multiple', 'medications', 'that', 'she', 'takes', 'and', 'it', 'is', 'very', 'difficult', 'to', 'keep', 'an', 'adequate', 'level', 'of', 'anticoagulation', 'that', 'is', 'safe', 'for', 'her', 'she', 'is', 'prone', 'to', 'a', 'fall', 'and', 'this', 'would', 'be', 'a', 'big', 'problem', 'we', 'will', 'use', 'one', 'aspirin', 'a', 'day', 'instead', 'of', 'the', 'anticoagulation', 'she', 'is', 'aware', 'of', 'the', 'risk', 'of', 'stroke', 'but', 'she', 'is', 'very', 'scared', 'of', 'the', 'anticoagulation', 'with', 'coumadin', 'and', 'does', 'not', 'want', 'to', 'use', 'the', 'coumadin', 'at', 'this', 'time', 'and', 'i', 'understand', 'we', 'will', 'see', 'her', 'as', 'an', 'outpatient']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization + Lowercase + (optional punctuation remover)\n",
        "\n"
      ],
      "metadata": {
        "id": "6RSDG8iYIdnw"
      },
      "id": "6RSDG8iYIdnw"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "tag_map = defaultdict(lambda : wordnet.NOUN)\n",
        "# note that we only can lemmatize certain types of words such as Adjectives,\n",
        "#   Verbs and Adverbs. Thus, we can ignore all others.\n",
        "tag_map['J'] = wordnet.ADJ \n",
        "tag_map['V'] = wordnet.VERB\n",
        "tag_map['R'] = wordnet.ADV\n",
        "\n",
        "# creating a lemmatizer object that we will use from the WordNetLemmatizer class\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YFQ-L8iKXKQ",
        "outputId": "e08d2dd2-c38c-450a-d960-b1cf0651cf4e"
      },
      "id": "8YFQ-L8iKXKQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess_document(document) takes a document (string) and applies different\n",
        "#   preprocessing functions such as lower case, tokenization, lemmatization, \n",
        "#   and an optional punctuation remover.\n",
        "# Returns: Array of tokens (strings)\n",
        "def preprocess_document(document):\n",
        "  # *** removes punctuation              \n",
        "  tokens = lower_punct_tokenize(document)\n",
        "\n",
        "  # tagged tokens returns a structure with 2 parameters (tuple) with the token\n",
        "  #   itself and the type of word it is\n",
        "  tagged_tokens = nltk.pos_tag(tokens)\n",
        "\n",
        "  # we will keep track of the array of lemmas\n",
        "  lemmas=[]\n",
        "\n",
        "  for token, pos in tagged_tokens:\n",
        "    # taking first letter of pos to check for possible match in tag_map\n",
        "    lemmatizer_tag = tag_map[pos[0]]\n",
        "    # the lemmatizer takes in a token and a pos argument\n",
        "    lemma = lemmatizer.lemmatize(token, pos=lemmatizer_tag)\n",
        "    lemmas.append(lemma)\n",
        "  return lemmas"
      ],
      "metadata": {
        "id": "Ytnz72ggKtRC"
      },
      "id": "Ytnz72ggKtRC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess corupus function (template function)\n",
        "\n",
        "\n",
        "*   Add on Machine/Deep learning model to classify processed data\n",
        "\n"
      ],
      "metadata": {
        "id": "W5D_GM5GQ4Fv"
      },
      "id": "W5D_GM5GQ4Fv"
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess_corpus(corpus) takes an array of documents (corpus) and applies \n",
        "#   and preprocess each of them in a for-loop. \n",
        "# *** This is a template function that can be used later\n",
        "def preprocess_corpus(corpus):\n",
        "  for document in corpus:\n",
        "    preprocess_document(document)\n",
        "    # then do something with the preprocessed document\n",
        "    "
      ],
      "metadata": {
        "id": "-SIxjpp0Q7j2"
      },
      "id": "-SIxjpp0Q7j2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test preprocess_document"
      ],
      "metadata": {
        "id": "bGq6RkaVQ1k8"
      },
      "id": "bGq6RkaVQ1k8"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"document itself: {train_df.transcription[0]}\")\n",
        "print(f\"after preprocess: {preprocess_document(train_df.transcription[0])}\")\n",
        "print(f\"after preprocess: {preprocess_document(train_df.transcription)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "uWwXFeLFM4q6",
        "outputId": "f5d19f5f-3a42-4673-b106-ce8985a08ada"
      },
      "id": "uWwXFeLFM4q6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document itself: REASON FOR THE VISIT:,  Very high PT/INR.,HISTORY: , The patient is an 81-year-old lady whom I met last month when she came in with pneumonia and CHF.  She was noticed to be in atrial fibrillation, which is a chronic problem for her.  She did not want to have Coumadin started because she said that she has had it before and the INR has had been very difficult to regulate to the point that it was dangerous, but I convinced her to restart the Coumadin again.  I gave her the Coumadin as an outpatient and then the INR was found to be 12.  So, I told her to come to the emergency room to get vitamin K to reverse the anticoagulation.,PAST MEDICAL HISTORY:,1.  Congestive heart failure.,2.  Renal insufficiency.,3.  Coronary artery disease.,4.  Atrial fibrillation.,5.  COPD.,6.  Recent pneumonia.,7.  Bladder cancer.,8.  History of ruptured colon.,9.  Myocardial infarction.,10.  Hernia repair.,11.  Colon resection.,12.  Carpal tunnel repair.,13.  Knee surgery.,MEDICATIONS:,1.  Coumadin.,2.  Simvastatin.,3.  Nitrofurantoin.,4.  Celebrex.,5.  Digoxin.,6.  Levothyroxine.,7.  Vicodin.,8.  Triamterene and hydrochlorothiazide.,9.  Carvedilol.,SOCIAL HISTORY:  ,She does not smoke and she does not drink.,PHYSICAL EXAMINATION:,GENERAL:  Lady in no distress.,VITAL SIGNS:  Blood pressure 100/46, pulse of 75, respirations 12, and temperature 98.2.,HEENT:  Head is normal.,NECK:  Supple.,LUNGS:  Clear to auscultation and percussion.,HEART:  No S3, no S4, and no murmurs.,ABDOMEN:  Soft.,EXTREMITIES:  Lower extremities, no edema.,ASSESSMENT:,1.  Atrial fibrillation.,2.  Coagulopathy, induced by Coumadin.,PLAN: , Her INR at the office was 12.  I will repeat it, and if it is still elevated, I will give vitamin K 10 mg in 100 mL of D5W and then send her home and repeat the PT/INR next week.  I believe at this time that it is too risky to use Coumadin in her case because of her age and comorbidities, the multiple medications that she takes and it is very difficult to keep an adequate level of anticoagulation that is safe for her.  She is prone to a fall and this would be a big problem.  We will use one aspirin a day instead of the anticoagulation.  She is aware of the risk of stroke, but she is very scared of the anticoagulation with Coumadin and does not want to use the Coumadin at this time and I understand.  We will see her as an outpatient.\n",
            "after preprocess: ['reason', 'for', 'the', 'visit', 'very', 'high', 'pt', 'inr', 'history', 'the', 'patient', 'be', 'an', '81', 'year', 'old', 'lady', 'whom', 'i', 'meet', 'last', 'month', 'when', 'she', 'come', 'in', 'with', 'pneumonia', 'and', 'chf', 'she', 'be', 'notice', 'to', 'be', 'in', 'atrial', 'fibrillation', 'which', 'be', 'a', 'chronic', 'problem', 'for', 'her', 'she', 'do', 'not', 'want', 'to', 'have', 'coumadin', 'start', 'because', 'she', 'say', 'that', 'she', 'have', 'have', 'it', 'before', 'and', 'the', 'inr', 'have', 'have', 'be', 'very', 'difficult', 'to', 'regulate', 'to', 'the', 'point', 'that', 'it', 'be', 'dangerous', 'but', 'i', 'convince', 'her', 'to', 'restart', 'the', 'coumadin', 'again', 'i', 'give', 'her', 'the', 'coumadin', 'a', 'an', 'outpatient', 'and', 'then', 'the', 'inr', 'be', 'find', 'to', 'be', '12', 'so', 'i', 'tell', 'her', 'to', 'come', 'to', 'the', 'emergency', 'room', 'to', 'get', 'vitamin', 'k', 'to', 'reverse', 'the', 'anticoagulation', 'past', 'medical', 'history', '1', 'congestive', 'heart', 'failure', '2', 'renal', 'insufficiency', '3', 'coronary', 'artery', 'disease', '4', 'atrial', 'fibrillation', '5', 'copd', '6', 'recent', 'pneumonia', '7', 'bladder', 'cancer', '8', 'history', 'of', 'ruptured', 'colon', '9', 'myocardial', 'infarction', '10', 'hernia', 'repair', '11', 'colon', 'resection', '12', 'carpal', 'tunnel', 'repair', '13', 'knee', 'surgery', 'medication', '1', 'coumadin', '2', 'simvastatin', '3', 'nitrofurantoin', '4', 'celebrex', '5', 'digoxin', '6', 'levothyroxine', '7', 'vicodin', '8', 'triamterene', 'and', 'hydrochlorothiazide', '9', 'carvedilol', 'social', 'history', 'she', 'do', 'not', 'smoke', 'and', 'she', 'do', 'not', 'drink', 'physical', 'examination', 'general', 'lady', 'in', 'no', 'distress', 'vital', 'sign', 'blood', 'pressure', '100', '46', 'pulse', 'of', '75', 'respiration', '12', 'and', 'temperature', '98', '2', 'heent', 'head', 'be', 'normal', 'neck', 'supple', 'lung', 'clear', 'to', 'auscultation', 'and', 'percussion', 'heart', 'no', 's3', 'no', 's4', 'and', 'no', 'murmur', 'abdomen', 'soft', 'extremity', 'low', 'extremities', 'no', 'edema', 'assessment', '1', 'atrial', 'fibrillation', '2', 'coagulopathy', 'induce', 'by', 'coumadin', 'plan', 'her', 'inr', 'at', 'the', 'office', 'be', '12', 'i', 'will', 'repeat', 'it', 'and', 'if', 'it', 'be', 'still', 'elevate', 'i', 'will', 'give', 'vitamin', 'k', '10', 'mg', 'in', '100', 'ml', 'of', 'd5w', 'and', 'then', 'send', 'her', 'home', 'and', 'repeat', 'the', 'pt', 'inr', 'next', 'week', 'i', 'believe', 'at', 'this', 'time', 'that', 'it', 'be', 'too', 'risky', 'to', 'use', 'coumadin', 'in', 'her', 'case', 'because', 'of', 'her', 'age', 'and', 'comorbidities', 'the', 'multiple', 'medication', 'that', 'she', 'take', 'and', 'it', 'be', 'very', 'difficult', 'to', 'keep', 'an', 'adequate', 'level', 'of', 'anticoagulation', 'that', 'be', 'safe', 'for', 'her', 'she', 'be', 'prone', 'to', 'a', 'fall', 'and', 'this', 'would', 'be', 'a', 'big', 'problem', 'we', 'will', 'use', 'one', 'aspirin', 'a', 'day', 'instead', 'of', 'the', 'anticoagulation', 'she', 'be', 'aware', 'of', 'the', 'risk', 'of', 'stroke', 'but', 'she', 'be', 'very', 'scared', 'of', 'the', 'anticoagulation', 'with', 'coumadin', 'and', 'do', 'not', 'want', 'to', 'use', 'the', 'coumadin', 'at', 'this', 'time', 'and', 'i', 'understand', 'we', 'will', 'see', 'her', 'a', 'an', 'outpatient']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d3a806fd7549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"document itself: {train_df.transcription[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"after preprocess: {preprocess_document(train_df.transcription[0])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"after preprocess: {preprocess_document(train_df.transcription)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-0c65d3978b91>\u001b[0m in \u001b[0;36mpreprocess_document\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# *** removes punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower_punct_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# tagged tokens returns a structure with 2 parameters (tuple) with the token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1a9a547b1b47>\u001b[0m in \u001b[0;36mlower_punct_tokenize\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlower_punct_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mlower_case_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_case_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 - Feature Engineering"
      ],
      "metadata": {
        "id": "VQXkjAyO4gGm"
      },
      "id": "VQXkjAyO4gGm"
    },
    {
      "cell_type": "markdown",
      "id": "0f1b6f4d",
      "metadata": {
        "id": "0f1b6f4d"
      },
      "source": [
        "### Sample Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68977658",
      "metadata": {
        "id": "68977658"
      },
      "outputs": [],
      "source": [
        "from datasets.dataset_dict import DatasetDict\n",
        "from datasets import Dataset\n",
        "from torch import nn\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e142223",
      "metadata": {
        "id": "3e142223"
      },
      "outputs": [],
      "source": [
        "unique_classes = train_df[\"medical_specialty\"].unique()\n",
        "\n",
        "# idx_2_class = {i: s for i, s in enumerate(unique_classes)}\n",
        "# class_2_idx = {s: i for i, s in enumerate(unique_classes)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac5d380",
      "metadata": {
        "id": "cac5d380"
      },
      "outputs": [],
      "source": [
        "# train_df[\"labels\"] = train_df[\"medical_specialty\"].apply(lambda s: class_2_idx[s])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233a4365",
      "metadata": {
        "id": "233a4365"
      },
      "outputs": [],
      "source": [
        "train_train_df, train_test_df = \\\n",
        "    train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449f16bd",
      "metadata": {
        "id": "449f16bd"
      },
      "outputs": [],
      "source": [
        "ds_dict = {\n",
        "    'train': Dataset.from_pandas(train_train_df),\n",
        "    'val': Dataset.from_pandas(train_test_df),\n",
        "    \"test\": Dataset.from_pandas(test_df)\n",
        "}\n",
        "\n",
        "ds = DatasetDict(ds_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a995f402",
      "metadata": {
        "scrolled": true,
        "id": "a995f402"
      },
      "outputs": [],
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_text(texts):\n",
        "    return tokenizer(texts[\"transcription\"], truncation=True, padding=True, max_length=256)\n",
        "\n",
        "ds[\"train\"] = ds[\"train\"].map(tokenize_text, batched=True)\n",
        "ds[\"val\"] = ds[\"val\"].map(tokenize_text, batched=True)\n",
        "ds[\"test\"] = ds[\"test\"].map(tokenize_text, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6c4319",
      "metadata": {
        "id": "fa6c4319"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(unique_classes)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22ca876",
      "metadata": {
        "id": "e22ca876"
      },
      "source": [
        "### Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f26fe53",
      "metadata": {
        "id": "1f26fe53"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "    return {\"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414f5205",
      "metadata": {
        "id": "414f5205"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "logging_steps = len(train_train_df) // batch_size\n",
        "output_dir = \"hf_trainer\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "     num_train_epochs=5,\n",
        "     learning_rate=2e-5,\n",
        "     per_device_train_batch_size=batch_size,\n",
        "     per_device_eval_batch_size=batch_size,\n",
        "     weight_decay=0.01,\n",
        "     evaluation_strategy=\"epoch\",\n",
        "     logging_steps=logging_steps,\n",
        "     push_to_hub=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994876be",
      "metadata": {
        "id": "994876be"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds['val'],\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cfca94",
      "metadata": {
        "id": "c8cfca94"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a6603a",
      "metadata": {
        "id": "e0a6603a"
      },
      "source": [
        "### Making Inference on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bc4a1d",
      "metadata": {
        "id": "d3bc4a1d"
      },
      "outputs": [],
      "source": [
        "ds[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d1f4da",
      "metadata": {
        "id": "d0d1f4da"
      },
      "outputs": [],
      "source": [
        "pred_y = trainer.predict(ds[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0411c232",
      "metadata": {
        "id": "0411c232"
      },
      "outputs": [],
      "source": [
        "a = pd.Series(pred_y.predictions.argmax(axis=1))\n",
        "a.name = \"Expected\"\n",
        "a.to_csv(\"predictions.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}